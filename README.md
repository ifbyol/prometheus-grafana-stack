# prometheus-grafana-stack

This is an example of Okteto manifest to have a Prometheus and Grafana consuming the metrics generated by an Okteto instance through Okteto Insights feature.

It deploy a simple Prometheus server (it doesn't deploy any of the other Prometheus components). It connects to the Okteto instance through 2 environment variables that have to specified when deploying it:
* `OKTETO_INSIGHTS_INSTANCE`: It is the hostname and port of the Okteto instance to be connected to Prometheus. An example would be `okteto.example.com:443`.
* `OKTETO_INSIGHTS_TOKEN`: It is the token to connect Prometheus for the authenticated `/metrics` endpoint exposed by the Okteto instance. You can get this token for the secret specified in the helm char value `insights.bearerSecret`.

> This is not intended to be a production ready instance to use. This is an example of how to configure Prometheus and Grafana together to consume Okteto Insights metrics. By default, Prometheus is deployed without any other component and with only 10Gb of persistence.

## How to deploy

You can deploy it from the Okteto UI or the CLI.

To do it via CLI, you just need to connect your CLI with the cluster where you want it to deploy:

```bash
okteto ctx use <okteto-instance-url>
```

And then, deploy it passing the needed variables:

```bash
okteto deploy --var=OKTETO_INSIGHTS_INSTANCE=<instance-hostname> --var=OKTETO_INSIGHTS_TOKEN=<token>
```

If you want to deploy it via the UI, you just need to login into your instance, go to the namespace you want and click on `Launch Dev Environment` option. Once there, you just go to `Git URL` tab and fill the modal with the repository URL and don't forget to specify the variables.

## Predefined dashboard

In `grafana/dashboards/okteto-insights.json` there is a dashboard with some graphs predefined to start visualizing some data exposed by Okteto Insights.

In those graphs you can see:
* % of memory requested compared to the total available per node
* % of memory used compared to the total available per node
* % of memory used compared to the requested per node
* % of CPU requested compared to the total available per node
* % of CPU used compared to the total available per node
* % of CPU used compared to the requested per node
* Evolution over time of memory (usage, requested and total) per node
* Evolution over time of CPU (usage, requested and total) per node
* Evolution over time in the number of nodes